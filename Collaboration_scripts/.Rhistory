normalization.method="SCT",
sct.clip.range=NULL,
reduction="rpca", #"cca", "jpca", "rlsi"
l2.norm=TRUE,
dims=1:30)
#******STEP 7E: FIND OPTIMUM k.weight FOR USE IN Seurat::IntegrateData()*****#
# Find minimum anchors between 2 datasets
kweight1 <- as.data.frame(integ_anchors@anchors) %>%
dplyr::group_by(dataset1, dataset2) %>%
distinct_at("cell1", .keep_all=TRUE) %>%
dplyr::summarize(n=n()) %>%
dplyr::ungroup() %>%
dplyr::select(n) %>%
unlist(use.names=FALSE) %>%
min()
# Find half of number of cells in sample with least cell count
kweight2 <- filtered.seurat@meta.data %>%
dplyr::count(Sample) %>%
dplyr::filter(n >=50) %>%
dplyr::select(n) %>%
unlist(use.names=FALSE) %>%
min()
kweight2 <- floor(kweight2/2)
kweight <- base::min(kweight1, kweight2, 100)
dplyr::if_else(kweight >= 100, 100, kweight)
cat("\n", celltype, "\tkweight1:", kweight1, "\tkweight2:", kweight2, "\tkweight:",  kweight, "\n")
# NOTE: Integration will not fail anymore. If it fails, identify the 2
# datasets that are involved in the error and use kweight=number of anchors
# for these 2 datasets.
cat("\nNumber of unique anchors between datasets\n")
print(as.data.frame(integ_anchors@anchors) %>%
dplyr::group_by(dataset1, dataset2) %>%
distinct_at("cell1", .keep_all=TRUE) %>%
dplyr::summarize(n=n()), n=1000)
#************************STEP 7F: INTEGRATE THE DATA*************************#
# NOTE: weight.reduction=NULL means new PCA will be calculated & used to
# calculate anchor weights
integrated.seurat.rpca <- Seurat::IntegrateData(anchorset=integ_anchors.rpca,
new.assay.name="integrated",
normalization.method="SCT",
features=NULL,
features.to.integrate=NULL,
dims=1:30,
k.weight=kweight, #default is 100
weight.reduction=NULL,
sd.weight=1)
#**STEP 7G: RUN PCA USING 3000 INTEGRATION FEATURES & UMAP USING FIRST 40 PCs**#
integrated.seurat <- Seurat::RunPCA(object=integrated.seurat,
assay="integrated",
features=NULL)
integrated.seurat <- Seurat::RunUMAP(object=integrated.seurat,
dims=1:40,
reduction="pca")
return(integrated.seurat)
}
# DEPRECATED (used during Seurat v3)
### Generate whitelist for CITESeq
# Input is filtered seurat object
# Output is a list of csv files - one per batch containing valid barcodes
v3_generate_whitelist <- function(filtered.seurat, output_path){
# Extract barcodes and split by "_"
bc <- filtered.seurat@meta.data$Cell
# Adjust this based on how your samples are named
# NOTE: There will be multiple samples within each batch
barcodes <- data.frame(stringr::str_split_fixed(bc, "_", 2)) %>%
dplyr::rename(Batch = identity(1), Barcodes = identity(2)) %>%
dplyr::mutate(Barcodes = stringr::str_replace(Barcodes, "-1", ""),
Batch = gsub(pattern="-GEX.*", replacement="", x=Batch))
# Remove duplicate barcodes within each batch
barcodes <- barcodes %>%
dplyr::group_by(Batch) %>%
dplyr::distinct_at("Barcodes", .keep_all=TRUE) %>%
as.data.frame()
# Check how many barcodes are present in each batch
barcodes %>% dplyr::group_by(Batch) %>% dplyr::count()
# Save barcodes from each batch to individual csv files
for (i in unique(barcodes$Batch)){
whitelist <- barcodes %>%
dplyr::filter(Batch == i) %>%
dplyr::select(Barcodes)
write.table(x = whitelist,
file = paste0(scripts_path, proj, "_", i, "_whitelist.csv"),
row.names = FALSE,
col.names = FALSE)
}
}
# DEPRECATED (used during Seurat v3)
# Input is path to folder containing h5ad
# Output is a raw seurat object
v3_read_h5ad <- function(input_path){
# Load h5ad (useful if analyzing collaborator data in h5ad format)
SeuratDisk::Convert(source = paste0(input_path, proj, ".h5ad"),
dest = "h5seurat",
assay="RNA",
overwrite = FALSE)
raw_seurat <- SeuratDisk::LoadH5Seurat(file = paste0(input_path, proj, ".h5seurat"))
return(raw_seurat)
}
### Import data from output of citeseq
# Input is path to demux_results folder
# Ouput is seurat object of each sample
v3_read_citeseq <- function(input_path){
# Create a list of samples that have been demultiplexed already
files <- list.files(path = paste0(input_path, "singlets/"),
full.names = FALSE)
samples <- gsub(pattern="\\..*", replacement="", x=files)
# Loop through each of the individual object in demux directory & import data
for (i in 1:length(files)){
# Read the seurat object containing demultiplexed singlets
sample.seurat <- readRDS(file = paste0(demux_results, "singlets/", files[i]))
# Assign the seurat object to its corresponding variable
assign(samples[i], sample.seurat)
}
}
SpatialFeaturePlotBlend <- function(cells_obj, column_1, column_2, combine=TRUE){
# Convert decimal number to hexadecimal. Pad with 0s if only a single
# character following conversion.
as_hex <- function(num) {
hex_str <- as.character(as.hexmode(num))
if (nchar(hex_str) == 1) {
hex_str <- paste0("0", hex_str)
}
return(hex_str)
}
metadata_to_hexadecimal <- function(in_dat) {
apply(in_dat, 2,
function(x) {
# Make minimum 0
x - min(x)
}) %>%
apply(2,
function(x) {
# Constrain to range [0, 255]
round(255 * (x / max(x)))
}) %>%
apply(1,
function(x) {
# Convert to hexadecimal codes
toupper(paste0("#", as_hex(x[1]), as_hex(x[2]), "00"))
})
}
blend_plot_theme <- theme(legend.position="none",
plot.title=element_text(hjust=0.5))
plot_list <- lapply(c(column_1, column_2),
function(column) {
max_color <- if_else(column == column_1,
"#FF0000", "#00FF00")
SpatialFeaturePlot(cells_obj, column) +
scale_fill_gradient(low="#000000",
high=max_color) +
ggtitle(column) +
blend_plot_theme
})
dat <- FetchData(cells_obj, c(column_1, column_2))
colors <- as.matrix(dat) %>% metadata_to_hexadecimal()
new_md_column <- paste0(column_1, "_vs_", column_2)
cells_obj[[new_md_column]] <- colors
names(colors) <- as.character(colors)
plot_list[[3]] <- SpatialDimPlot(cells_obj, new_md_column, cols=colors) +
ggtitle(paste0(column_1, "_", column_2)) +
blend_plot_theme
side_length <- 100
legend_grid <- expand.grid(seq(from=min(dat[, column_1]),
to=max(dat[, column_1]),
length.out=side_length),
seq(from=min(dat[, column_2]),
to=max(dat[, column_2]),
length.out=side_length))
colnames(legend_grid) <- c(column_1, column_2)
legend_colors <- metadata_to_hexadecimal(legend_grid)
legend_grid$color <- legend_colors
names(legend_colors) <- legend_colors
legend <- ggplot(legend_grid,
aes(x=.data[[column_1]], y=.data[[column_2]],
color=color)) +
geom_point(shape=15, size=1.9) +
scale_color_manual(values=legend_colors) +
coord_cartesian(expand=FALSE) +
theme(legend.position="none", aspect.ratio=1,
panel.background=element_blank())
plot_list[[4]] <- wrap_plots(ggplot() + theme_void(), legend,
ggplot() + theme_void(), ncol=1,
heights=c(0.2, 0.6, 0.2))
if (combine == FALSE) {
return(plot_list)
} else {
p <- wrap_plots(plot_list, nrow=1,
widths=c(0.28, 0.28, 0.28, 0.16))
return(p)
}
}
proj.dir <- "C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/Collaboration projects data/Kamya_IMC"
# df1 <- openxlsx::read.xlsx(file.path(proj.dir, "Simian Files/name_mapping.xlsx"))
# df2 <- openxlsx::read.xlsx(file.path(proj.dir, "KS_LiverMets_Cohort2_clinicalinfo 08.15.25 - de-identified.xlsx"))
# df <- dplyr::full_join(df1, df2, by=c("PatientID"="PatientID"))
df <- openxlsx::read.xlsx(file.path(proj.dir, "Metadata.xlsx"))
df$DateBirth <- openxlsx::convertToDate(df$DateBirth)
df$DateDiagnosis <- openxlsx::convertToDate(df$DateDiagnosis)
df$DateSurgery <- openxlsx::convertToDate(df$DateSurgery)
df$DateDeath <- openxlsx::convertToDate(df$DateDeath)
df$DateLastFollowUp <- openxlsx::convertToDate(df$DateLastFollowUp)
df$DateImmunotherapyStart <- openxlsx::convertToDate(df$DateImmunotherapyStart)
df <- df %>% dplyr::mutate(OS = dplyr::case_when(!is.na(DateDeath) ~ DateDeath - DateDiagnosis,
!is.na(DateLastFollowUp) ~ DateLastFollowUp -DateDiagnosis,
TRUE ~ NA),
DPS = dplyr::case_when(!is.na(DateDeath) ~ DateDeath - DateSurgery,
!is.na(DateLastFollowUp) ~ DateLastFollowUp - DateSurgery,
TRUE ~ NA)) %>%
dplyr::select(SlideName, DateName, SurgicalAccession, PatientID, SlideID,
AnonymID, DateBirth, DateDeath, DateLastFollowUp, DateDiagnosis,
DateSurgery, Status, OS, DPS, AgeDiagnosis, StageDiagnosis,
everything())
test_variables <- c("SlideName", "AnonymID", "OS", "Status")
meta_data <- df %>%
dplyr::select(all_of(test_variables), -SlideID) %>%
dplyr::mutate(Sample_ID = as.character(AnonymID), Time = as.numeric(OS)/30.44) %>%
dplyr::filter(!is.na(Time), !is.na(Status), !is.na(SlideName))
expr <- openxlsx::read.xlsx(file.path(proj.dir, "cell_norm_expression.xlsx"))
marker_cols <- colnames(expr)[13:ncol(expr)]
expr_metapheno <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::group_by(AnonymID, metapheno) %>%
dplyr::summarise(across(all_of(marker_cols), mean, na.rm = TRUE),.groups = "drop")
metapheno_groups <- unique(expr_metapheno$metapheno)
expr_pheno <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::group_by(AnonymID, pheno) %>%
dplyr::summarise(across(all_of(marker_cols), mean, na.rm = TRUE),.groups = "drop")
pheno_groups <- unique(expr_pheno$pheno)
device.off()
for (group in pheno_groups)  {
expr_data <- expr_pheno %>%
dplyr::filter(pheno == group) %>%
dplyr::select(-pheno) %>%
tibble::column_to_rownames("AnonymID") %>%
t()
survival_params <- list(
# ---- Stratification (Expression + Metadata-based survival) ----
stratify_var     = marker_cols,          # one or more genes or metadata columns
sig_score        = FALSE,          # TRUE = combine genes into one signature score
substratify_var  = NULL,          # optional metadata column for sub-stratification
facet_var        = NULL,          # optional faceting variable
# ---- Cutoff settings (ONLY for Expression-based survival) ----
cutoff_method    = "optimal",      # mean, median, quartile, tertile, optimal, thirds
show_all_bins    = FALSE,          # TRUE = plot all bins (LOW, HIGH, MID/MED_HIGH/MED_LOW)
multiple_cutoff  = FALSE,          # TRUE = compute cutoffs separately for substratify_var
# ---- Plot settings ----
conf_interval    = FALSE,          # TRUE = show confidence interval in survival curve
plot_curve       = TRUE,           # TRUE = plot the survival curve
plot_risk_table  = TRUE,           # TRUE = plot the risk table below the curve
color_palette    = custom_palette, # vector of colors for groups c("#d73027","#0c2c84")
# ---- Survival data columns ----
time_col         = "Time",         # metadata column containing Time values
status_col       = "Status",       # metadata column containing Status values
# ---- Output ----
prefix           = "",
#output_path      = "C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop"
#output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/metapheno1", group)
output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/pheno1", group)
)
survival_analysis(meta_data, expr_data, survival_params)
}
View(survival_params)
View(expr_data)
# Calculate cox model stats (HR, CI, p vals) for each facet
calc_cox_stats <- function(facet_df, stratify_var, surv_formula, survival_params){
# ---- Cox model ----
# Ensure model column is a factor
model_col <- paste0("model_", stratify_var)
facet_df[[model_col]] <- factor(facet_df[[model_col]])
# Fit Cox model
cox_model <- survival::coxph(formula = surv_formula, data = facet_df)
# Cox model coefficients
cox_coef_df <- summary(cox_model)$coefficients
cox_ci_df <- as.data.frame(confint(cox_model))
baseline <- levels(facet_df[[model_col]])[1]  # the factor baseline
cox_df <- data.frame(Gene = stratify_var,
Target = gsub(paste0("^model_", stratify_var), "", rownames(cox_coef_df)), # remove "model" prefix if present
Reference = baseline,
HR = exp(cox_coef_df[, "coef"]),
CI_lower = exp(cox_ci_df[, 1]),
CI_upper = exp(cox_ci_df[, 2]),
pval = cox_coef_df[, "Pr(>|z|)"],
stringsAsFactors = FALSE) %>%
dplyr::mutate(contrast = paste0(Target, " / ", Reference)) %>%
dplyr::select(Gene, contrast, HR, pval, CI_lower, CI_upper, Target, Reference) %>%
tibble::remove_rownames()
# ---- Optional: emmeans for pairwise contrasts ----
# Step 1: estimated marginal means on log-hazard scale
emm <- emmeans::emmeans(object = cox_model, specs = as.formula(paste0("~", model_col)))
# Step 2: pairwise contrasts on HR scale
pairwise <- emmeans::contrast(object = emm, method = "pairwise", type = "response")
# Step 3: add confidence intervals
pairwise_ci <- stats::confint(pairwise)
# Step 4: combine into clean data.frame
pairwise_df <- dplyr::left_join(x = as.data.frame(pairwise) %>%
dplyr::select(contrast, ratio, p.value),
y = as.data.frame(pairwise_ci) %>%
dplyr::select(contrast, asymp.LCL, asymp.UCL),
by = c("contrast"="contrast")) %>%
dplyr::rename(HR = ratio,
CI_lower = asymp.LCL,
CI_upper = asymp.UCL,
pval = p.value) %>%
dplyr::mutate(Target = sub(" / .*", "", contrast),
Reference = sub(".* / ", "", contrast),
Gene = stratify_var)
# Step 5: Calculate HR, CI for reverse contrasts
reversed <- pairwise_df %>%
dplyr::mutate(Reference = sub(" / .*", "", contrast),
Target = sub(".* / ", "", contrast),
contrast = paste(Target, "/", Reference),
# reciprocal HR
HR = 1 / HR,
# swap CI bounds
CI_lower = 1 / CI_upper,
CI_upper = 1 / CI_lower)
# Step 6: Merge all stats
emmeans_df <- dplyr::bind_rows(pairwise_df, reversed)
# Step 7: Compute non-parametric p-values
emmeans_df <- sapply(X = emmeans_df$contrast, FUN = calc_pvals,
stratify_var =  stratify_var,
facet_df = facet_df, survival_params = survival_params) %>%
t() %>%
as.data.frame() %>%
tibble::rownames_to_column("contrast") %>%
dplyr::right_join(emmeans_df, by=c("contrast" = "contrast")) %>%
dplyr::select(Gene, contrast, Target, Reference, HR, pval, CI_lower, CI_upper, everything())
cox_df <- sapply(X = cox_df$contrast, FUN = calc_pvals,
stratify_var =  stratify_var,
facet_df = facet_df, survival_params = survival_params) %>%
t() %>%
as.data.frame() %>%
tibble::rownames_to_column("contrast") %>%
dplyr::right_join(cox_df, by=c("contrast" = "contrast")) %>%
dplyr::select(Gene, contrast, Target, Reference, HR, pval, CI_lower, CI_upper, everything())
# ---- Return both ----
list(cox_model_df = cox_df,
emmeans_df = emmeans_df)
}
dev.off()
for (group in pheno_groups)  {
expr_data <- expr_pheno %>%
dplyr::filter(pheno == group) %>%
dplyr::select(-pheno) %>%
tibble::column_to_rownames("AnonymID") %>%
t()
survival_params <- list(
# ---- Stratification (Expression + Metadata-based survival) ----
stratify_var     = marker_cols,          # one or more genes or metadata columns
sig_score        = FALSE,          # TRUE = combine genes into one signature score
substratify_var  = NULL,          # optional metadata column for sub-stratification
facet_var        = NULL,          # optional faceting variable
# ---- Cutoff settings (ONLY for Expression-based survival) ----
cutoff_method    = "optimal",      # mean, median, quartile, tertile, optimal, thirds
show_all_bins    = FALSE,          # TRUE = plot all bins (LOW, HIGH, MID/MED_HIGH/MED_LOW)
multiple_cutoff  = FALSE,          # TRUE = compute cutoffs separately for substratify_var
# ---- Plot settings ----
conf_interval    = FALSE,          # TRUE = show confidence interval in survival curve
plot_curve       = TRUE,           # TRUE = plot the survival curve
plot_risk_table  = TRUE,           # TRUE = plot the risk table below the curve
color_palette    = custom_palette, # vector of colors for groups c("#d73027","#0c2c84")
# ---- Survival data columns ----
time_col         = "Time",         # metadata column containing Time values
status_col       = "Status",       # metadata column containing Status values
# ---- Output ----
prefix           = "",
#output_path      = "C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop"
#output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/metapheno1", group)
output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/pheno1", group)
)
survival_analysis(meta_data, expr_data, survival_params)
}
marker_cols
for (group in metapheno_groups)  {
expr_data <- expr_metapheno %>%
dplyr::filter(metapheno == group) %>%
dplyr::select(-metapheno) %>%
tibble::column_to_rownames("AnonymID") %>%
t()
# for (group in pheno_groups)  {
#
#   expr_data <- expr_pheno %>%
#     dplyr::filter(pheno == group) %>%
#     dplyr::select(-pheno) %>%
#     tibble::column_to_rownames("AnonymID") %>%
#     t()
survival_params <- list(
# ---- Stratification (Expression + Metadata-based survival) ----
stratify_var     = marker_cols,          # one or more genes or metadata columns
sig_score        = FALSE,          # TRUE = combine genes into one signature score
substratify_var  = NULL,          # optional metadata column for sub-stratification
facet_var        = NULL,          # optional faceting variable
# ---- Cutoff settings (ONLY for Expression-based survival) ----
cutoff_method    = "optimal",      # mean, median, quartile, tertile, optimal, thirds
show_all_bins    = FALSE,          # TRUE = plot all bins (LOW, HIGH, MID/MED_HIGH/MED_LOW)
multiple_cutoff  = FALSE,          # TRUE = compute cutoffs separately for substratify_var
# ---- Plot settings ----
conf_interval    = FALSE,          # TRUE = show confidence interval in survival curve
plot_curve       = TRUE,           # TRUE = plot the survival curve
plot_risk_table  = TRUE,           # TRUE = plot the risk table below the curve
color_palette    = custom_palette, # vector of colors for groups c("#d73027","#0c2c84")
# ---- Survival data columns ----
time_col         = "Time",         # metadata column containing Time values
status_col       = "Status",       # metadata column containing Status values
# ---- Output ----
prefix           = "",
#output_path      = "C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop"
output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/metapheno1", group)
#output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/pheno1", group)
)
survival_analysis(meta_data, expr_data, survival_params)
}
expr_custom <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge")
View(expr_custom)
expr_custom <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::filter(pheno %in% c("T helper", "T cytotoxic"))
expr_custom <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::filter(pheno %in% c("T helper", "T cytotoxic")) %>%
dplyr::group_by(AnonymID) %>%
dplyr::summarise(across(all_of(marker_cols), mean, na.rm = TRUE),.groups = "drop")
unique(expr_pheno$pheno)
unique(expr_custom$pheno)
expr_custom <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::filter(pheno %in% c("T helper", "T cytotoxic")) %>%
dplyr::group_by(AnonymID) %>%
dplyr::summarise(across(all_of(marker_cols), mean, na.rm = TRUE),.groups = "drop")
expr
custom_groups <- "Tcell"
expr_custom <- expr %>%
tidyr::separate(col = txt,
into = c("DateName", "AnonymID", "SlideID", "ROI"),
sep = "_",
extra = "merge") %>%
dplyr::filter(pheno %in% c("T helper", "T cytotoxic")) %>%
dplyr::group_by(AnonymID) %>%
dplyr::summarise(across(all_of(marker_cols), mean, na.rm = TRUE),.groups = "drop") %>%
dplyr::mutate(pheno = "Tcell")
custom_groups <- unique(expr_custom$pheno)
expr_custom
for (group in custom_groups)  {
expr_data <- expr_custom %>%
dplyr::filter(pheno == group) %>%
dplyr::select(-pheno) %>%
tibble::column_to_rownames("AnonymID") %>%
t()
survival_params <- list(
# ---- Stratification (Expression + Metadata-based survival) ----
stratify_var     = marker_cols,          # one or more genes or metadata columns
sig_score        = FALSE,          # TRUE = combine genes into one signature score
substratify_var  = NULL,          # optional metadata column for sub-stratification
facet_var        = NULL,          # optional faceting variable
# ---- Cutoff settings (ONLY for Expression-based survival) ----
cutoff_method    = "optimal",      # mean, median, quartile, tertile, optimal, thirds
show_all_bins    = FALSE,          # TRUE = plot all bins (LOW, HIGH, MID/MED_HIGH/MED_LOW)
multiple_cutoff  = FALSE,          # TRUE = compute cutoffs separately for substratify_var
# ---- Plot settings ----
conf_interval    = FALSE,          # TRUE = show confidence interval in survival curve
plot_curve       = TRUE,           # TRUE = plot the survival curve
plot_risk_table  = TRUE,           # TRUE = plot the risk table below the curve
color_palette    = custom_palette, # vector of colors for groups c("#d73027","#0c2c84")
# ---- Survival data columns ----
time_col         = "Time",         # metadata column containing Time values
status_col       = "Status",       # metadata column containing Status values
# ---- Output ----
prefix           = "",
output_path      = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/custom", group)
#output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/metapheno1", group)
#output_path     = file.path("C:/Users/kailasamms/OneDrive - Cedars-Sinai Health System/Desktop/pheno1", group)
)
survival_analysis(meta_data, expr_data, survival_params)
}
View(expr)
expr %>% count(sctype, tissue, patient)
expr %>% count(sctype, tissue, patient) %>% arrange(patient)
View(meta_data)
View(meta_data)
View(df)
View(df)
View(df)
df %>% count(AnonymID)
df %>% count(PatientID)
df %>% count(SurgicalAccession)
df %>% count(SurgicalAccession) %>% filter(n>1)
View(expr)
View(meta_data)
View(meta_data)
View(meta_data)
expr %>% count(txt, sctype, tissue, patient) %>% arrange(patient)
View(df)
