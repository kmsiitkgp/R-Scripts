colnames(data) <- c("Sample", "values", "Condition")
# Use F.test() to determine if variances are equal or not.
# NOTE: p < 0.05 => unequal variance
# NOTE: If Iso <- c(NA, NA, 18) and IP <- c(17, NA, 18),
# var.test and t.test with throw error since Iso has only 1 value.
# NOTE: If Iso <- c(1,1,1) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
# NOTE: If Iso <- c(0,0,0) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
if (sum(!is.na(data[data$Condition == Reference, ]$values)) > 1 &
sum(!is.na(data[data$Condition == Target, ]$values)) > 1 &
(length(unique(data[data$Condition == Reference, ]$values)) +
length(unique(data[data$Condition == Target, ]$values)) > 2)){
#   f_test <- var.test(formula = values ~ Condition,
#                      data = data,
#                      alternative = "two.sided")
#
#   if(!is.na(f_test$p.value)){
# if (f_test$p.value < 0.05){
# t_test <- t.test(formula = values ~ Condition,
#                  data = data,
#                  alternative = "two.sided",
#                  var.equal = FALSE)
# }
# # Remove outliers
# ref_data <- data[data$Condition == Reference, ]$values
# low_ref <- quantile(ref_data, na.rm=TRUE)[2] - 1.5*IQR(ref_data, na.rm=TRUE)
# high_ref <- quantile(ref_data, na.rm=TRUE)[3] + 1.5*IQR(ref_data, na.rm=TRUE)
#
# target_data <- data[data$Condition == Target, ]$values
# low_tar <- quantile(target_data, na.rm=TRUE)[2] - 1.5*IQR(target_data, na.rm=TRUE)
# high_tar <- quantile(target_data, na.rm=TRUE)[3] + 1.5*IQR(target_data, na.rm=TRUE)
#
# data <- data %>%
#   dplyr::filter(!(Condition == Reference & (values > high_ref | values < low_ref))) %>%
#   dplyr::filter(!(Condition == Target & (values > high_tar | values < low_tar)))
# Calculate p values, mean expression
t_test <- t.test(formula = values ~ Condition,
data = data,
alternative = "two.sided",
var.equal = FALSE)
if (grepl(Reference, names(t_test$estimate[1]))){
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[1]])
expt <- c(expt, t_test$estimate[[2]])
} else if (grepl(Reference, names(t_test$estimate[2]))) {
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[2]])
expt <- c(expt, t_test$estimate[[1]])
}
} else{
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, 1) # Note: DO NOT SET to NA. It will increase padj.
control <- c(control, mean(data[data$Condition == Reference, ]$values, na.rm=TRUE))
expt <- c(expt, mean(data[data$Condition == Target, ]$values, na.rm=TRUE))
}
}
stats_df <- data.frame(genes, expt, control, pval)
stats_df$padj <- stats::p.adjust(p = stats_df$pval, method = "fdr", n = length(stats_df$pval))
stats_df$log2FC <- log2(1+stats_df$expt) - log2(1+stats_df$control)
result <- counts %>%
tibble::rownames_to_column(var = "Gene") %>%
dplyr::left_join(stats_df, by = c("Gene" = "genes"))
return(result)
}
# Calculate padj and log2FoldChange
Target <- "Yneg"
Reference <- "Ypos"
results <- calc_stats(data_mat, metadata, Target, Reference)
calc_stats <- function(counts, metadata, Target, Reference){
# Perform t.test
genes <- c()
expt <- c()
control <- c()
pval <- c()
for (j in 1:nrow(counts)){
data <- counts[j,] %>%
t() %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Sample") %>%
dplyr::left_join(metadata, by = c("Sample" = "Sample"))
colnames(data) <- c("Sample", "values", "Condition")
# Use F.test() to determine if variances are equal or not.
# NOTE: p < 0.05 => unequal variance
# NOTE: If Iso <- c(NA, NA, 18) and IP <- c(17, NA, 18),
# var.test and t.test with throw error since Iso has only 1 value.
# NOTE: If Iso <- c(1,1,1) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
# NOTE: If Iso <- c(0,0,0) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
if (sum(!is.na(data[data$Condition == Reference, ]$values)) > 1 &
sum(!is.na(data[data$Condition == Target, ]$values)) > 1 &
(length(unique(data[data$Condition == Reference, ]$values)) +
length(unique(data[data$Condition == Target, ]$values)) > 2)){
#   f_test <- var.test(formula = values ~ Condition,
#                      data = data,
#                      alternative = "two.sided")
#
#   if(!is.na(f_test$p.value)){
# if (f_test$p.value < 0.05){
# t_test <- t.test(formula = values ~ Condition,
#                  data = data,
#                  alternative = "two.sided",
#                  var.equal = FALSE)
# }
# # Remove outliers
# ref_data <- data[data$Condition == Reference, ]$values
# low_ref <- quantile(ref_data, na.rm=TRUE)[2] - 1.5*IQR(ref_data, na.rm=TRUE)
# high_ref <- quantile(ref_data, na.rm=TRUE)[3] + 1.5*IQR(ref_data, na.rm=TRUE)
#
# target_data <- data[data$Condition == Target, ]$values
# low_tar <- quantile(target_data, na.rm=TRUE)[2] - 1.5*IQR(target_data, na.rm=TRUE)
# high_tar <- quantile(target_data, na.rm=TRUE)[3] + 1.5*IQR(target_data, na.rm=TRUE)
#
# data <- data %>%
#   dplyr::filter(!(Condition == Reference & (values > high_ref | values < low_ref))) %>%
#   dplyr::filter(!(Condition == Target & (values > high_tar | values < low_tar)))
# Calculate p values, mean expression
t_test <- t.test(formula = values ~ Condition,
data = data,
alternative = "two.sided",
var.equal = FALSE)
if (grepl(Reference, names(t_test$estimate[1]))){
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[1]])
expt <- c(expt, t_test$estimate[[2]])
} else if (grepl(Reference, names(t_test$estimate[2]))) {
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[2]])
expt <- c(expt, t_test$estimate[[1]])
}
} else{
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, 1) # Note: DO NOT SET to NA. It will increase padj.
control <- c(control, mean(data[data$Condition == Reference, ]$values, na.rm=TRUE))
expt <- c(expt, mean(data[data$Condition == Target, ]$values, na.rm=TRUE))
}
}
stats_df <- data.frame(genes, expt, control, pval)
stats_df$padj <- stats::p.adjust(p = stats_df$pval, method = "fdr", n = length(stats_df$pval))
stats_df$log2FC <- log2(1+stats_df$expt) - log2(1+stats_df$control)
result <- counts %>%
tibble::rownames_to_column(var = "Gene") %>%
dplyr::left_join(stats_df, by = c("Gene" = "genes"))
return(result)
}
# Calculate padj and log2FoldChange
Target <- "Yneg"
Reference <- "Ypos"
results <- calc_stats(data_mat, metadata, Target, Reference)
impute_with_mean <- function(raw_counts){
# Replace NA with average
for (j in 1:nrow(raw_counts)){
data <- raw_counts[j,] %>%
t() %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Sample") %>%
dplyr::left_join(metadata, by = c("Sample" = "Sample"))
colnames(data) <- c("Sample", "values", "Condition")
# If all values for Reference == NA or Target == NA, set them to 0.
# Replace NA with average wherever possible.
data <- data %>%
dplyr::mutate(values = as.numeric(values)) %>%
dplyr::group_by(Condition) %>%
dplyr::mutate(average = mean(values, na.rm=TRUE)) %>%
dplyr::ungroup() %>%
dplyr::mutate(average = dplyr::if_else(is.na(average), 0, average),
values = dplyr::if_else(is.na(values), average, values))
data <- data %>%
dplyr::select(Sample, values) %>%
tibble::column_to_rownames("Sample") %>%
t()
if(all(colnames(data) == colnames(raw_counts))){
raw_counts[j,] <- data[,colnames(raw_counts[j,])] %>% unlist(use.names=FALSE)
}
}
imputed_counts <- raw_counts %>%
dplyr::mutate(across(.cols=everything(), .fns = as.numeric))
return(imputed_counts)
}
quantile_norm <- function(raw_counts, quant_norm){
# Perform quantile normalization
if (quant_norm == TRUE){
quant_norm_counts <- as.data.frame(preprocessCore::normalize.quantiles(as.matrix(raw_counts)))
rownames(quant_norm_counts) <- rownames(raw_counts)
colnames(quant_norm_counts) <- colnames(raw_counts)
} else {
quant_norm_counts <- raw_counts
}
return(quant_norm_counts)
}
calc_stats <- function(counts, metadata, Target, Reference){
# Perform t.test
genes <- c()
expt <- c()
control <- c()
pval <- c()
for (j in 1:nrow(counts)){
data <- counts[j,] %>%
t() %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Sample") %>%
dplyr::left_join(metadata, by = c("Sample" = "Sample"))
colnames(data) <- c("Sample", "values", "Condition")
# Use F.test() to determine if variances are equal or not.
# NOTE: p < 0.05 => unequal variance
# NOTE: If Iso <- c(NA, NA, 18) and IP <- c(17, NA, 18),
# var.test and t.test with throw error since Iso has only 1 value.
# NOTE: If Iso <- c(1,1,1) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
# NOTE: If Iso <- c(0,0,0) and IP <- c(1,1,1),
# t.test will throw error "data are essentially constant".
if (sum(!is.na(data[data$Condition == Reference, ]$values)) > 1 &
sum(!is.na(data[data$Condition == Target, ]$values)) > 1 &
(length(unique(data[data$Condition == Reference, ]$values)) +
length(unique(data[data$Condition == Target, ]$values)) > 2)){
#   f_test <- var.test(formula = values ~ Condition,
#                      data = data,
#                      alternative = "two.sided")
#
#   if(!is.na(f_test$p.value)){
# if (f_test$p.value < 0.05){
# t_test <- t.test(formula = values ~ Condition,
#                  data = data,
#                  alternative = "two.sided",
#                  var.equal = FALSE)
# }
# # Remove outliers
# ref_data <- data[data$Condition == Reference, ]$values
# low_ref <- quantile(ref_data, na.rm=TRUE)[2] - 1.5*IQR(ref_data, na.rm=TRUE)
# high_ref <- quantile(ref_data, na.rm=TRUE)[3] + 1.5*IQR(ref_data, na.rm=TRUE)
#
# target_data <- data[data$Condition == Target, ]$values
# low_tar <- quantile(target_data, na.rm=TRUE)[2] - 1.5*IQR(target_data, na.rm=TRUE)
# high_tar <- quantile(target_data, na.rm=TRUE)[3] + 1.5*IQR(target_data, na.rm=TRUE)
#
# data <- data %>%
#   dplyr::filter(!(Condition == Reference & (values > high_ref | values < low_ref))) %>%
#   dplyr::filter(!(Condition == Target & (values > high_tar | values < low_tar)))
# Calculate p values, mean expression
t_test <- t.test(formula = values ~ Condition,
data = data,
alternative = "two.sided",
var.equal = FALSE)
if (grepl(Reference, names(t_test$estimate[1]))){
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[1]])
expt <- c(expt, t_test$estimate[[2]])
} else if (grepl(Reference, names(t_test$estimate[2]))) {
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, t_test$p.value)
control <- c(control, t_test$estimate[[2]])
expt <- c(expt, t_test$estimate[[1]])
}
} else{
genes <- c(genes, rownames(raw_counts)[j])
pval <- c(pval, 1) # Note: DO NOT SET to NA. It will increase padj.
control <- c(control, mean(data[data$Condition == Reference, ]$values, na.rm=TRUE))
expt <- c(expt, mean(data[data$Condition == Target, ]$values, na.rm=TRUE))
}
}
stats_df <- data.frame(genes, expt, control, pval)
stats_df$padj <- stats::p.adjust(p = stats_df$pval, method = "fdr", n = length(stats_df$pval))
stats_df$log2FC <- log2(1+stats_df$expt) - log2(1+stats_df$control)
result <- counts %>%
tibble::rownames_to_column(var = "Gene") %>%
dplyr::left_join(stats_df, by = c("Gene" = "genes"))
return(result)
}
parent_path <- "C:/Users/kailasamms/Desktop/Collaboration projects/Prince/"
results_path <- parent_path
# Import raw counts
raw_counts <- read.xlsx(paste0(parent_path, "Results_id_YKO_centromere_vs_scr_KO_centromere_pg_matrix.xlsx"))
# Remove rows that have multiple genes or missing genes
raw_counts <- raw_counts[!grepl(pattern=";", x=raw_counts$Genes),] %>%
dplyr::filter(!is.na(Genes)) %>%
dplyr::arrange(Genes)
rownames(raw_counts) <- seq(1:nrow(raw_counts))
# Create metadata
metadata <- data.frame("Sample" = colnames(raw_counts)[-1],
"Condition" = c("Ypos","Ypos", "Ypos", "Yneg", "Yneg", "Yneg"))
# Notice that some genes have duplicates. This is because they correspond to
# different peptides detected by the mass spec algorithm. We keep the row that
# contains the highest intensity for most samples and discard rest of duplicates
dup_genes <- raw_counts %>%
dplyr::count(Genes) %>%
dplyr::filter(n>1) %>%
dplyr::select(Genes) %>%
unlist(use.names = FALSE)
# Create empty dataframe to store max intensities of duplicated genes
df <- data.frame(matrix(NA, nrow = 1, ncol = ncol(raw_counts)))
colnames(df) <- colnames(raw_counts)
# Iterate through each duplicated gene and find which row has max intensities
# across multiple samples
for (gene in dup_genes){
test <- raw_counts %>%
dplyr::filter(Genes %in% gene) %>%
base::replace(is.na(.), 0)
row_id <- c()
for (i in 2:ncol(test)){
row_id <- c(row_id, which.max(test[,i]))
}
row_id <- as.data.frame(table(row_id)) %>%
dplyr::slice_max(Freq) %>%  # if there are 2 max values both are selected
dplyr::select(row_id) %>%
unlist(use.names=FALSE) %>%
as.character() %>%
as.numeric()
df1 <- test[row_id,]
if (all(colnames(df) == colnames(df1))){
df <- dplyr::bind_rows(df,df1)
}
}
# Remove the dummy column with NAs
df <- df[-1,]
# If some genes still have 2 rows, average them
df <- df %>%
dplyr::group_by(Genes) %>%
summarize(across(.cols=everything(), .fns=mean)) %>%
dplyr::ungroup()
# Remove duplicated genes from raw_counts
raw_counts <- raw_counts %>%
dplyr::filter(!Genes %in% dup_genes)
# Add max values we calcualted to raw_counts
if (all(colnames(df) == colnames(raw_counts))){
raw_counts <- dplyr::bind_rows(df, raw_counts)
}
# Replace all 0 with NA again
raw_counts <- raw_counts %>%
dplyr::mutate(across(.cols=where(is.numeric), ~na_if(., 0))) %>%
tibble::column_to_rownames("Genes")
# Impute missing values in biological replicates
imputed_counts <- impute_with_mean(raw_counts)
# Perform quantile normalization
quant_norm <- TRUE
quant_norm_counts <- quantile_norm(imputed_counts, quant_norm)
# Calculate padj and log2FoldChange
Target <- "Yneg"
Reference <- "Ypos"
results <- calc_stats(quant_norm_counts, metadata, Target, Reference)
# Save the results
wb <- openxlsx::createWorkbook()
openxlsx::addWorksheet(wb, sheetName = "results")
openxlsx::writeData(wb, sheet = "results", x = results, rowNames = FALSE)
openxlsx::addWorksheet(wb, sheetName = "raw_intensites")
openxlsx::writeData(wb, sheet = "raw_intensites", x = raw_counts, rowNames=TRUE)
openxlsx::addWorksheet(wb, sheetName = "imputed_intensities")
openxlsx::writeData(wb, sheet = "imputed_intensities", x = imputed_counts, rowNames = FALSE)
openxlsx::addWorksheet(wb, sheetName = "quant_norm_intensities")
openxlsx::writeData(wb, sheet = "quant_norm_intensities", x = quant_norm_counts, rowNames = FALSE)
openxlsx::saveWorkbook(wb, file = paste0(results_path, "pg_matrix.xlsx"),
overwrite = TRUE)
DEGs_df <- read.xlsx(paste0(parent_path, "pg_matrix.xlsx"))
View(DEGs_df)
DEGs_df <- read.xlsx(paste0(parent_path, "pg_matrix.xlsx"))
# List all gmt files
gmt_files <- list.files("C:/Users/kailasamms/Documents/GitHub/R-Scripts/GSEA_genesets/Mouse", full.names = TRUE)
# Loop over each gmt file and perform GSEA analysis
for (f in gmt_files){
fgsea(DEGs_df, f)
}
fgsea <- function(DEGs_df, gmt_file){
#****************************************************************************#
#     PREPARE A RANKED GENE LIST OF ALL GENES EXPRESSED IN YOUR SAMPLES      #
#****************************************************************************#
# NOTE: ALL genes MUST be used for this analysis, NOT just DEGs.
# NOTE: Genes MUST be ranked i.e. sorted in descending fold change. You can
# also rank based on log2FC & p value like: sign(df$log2fc)*(-log10(df$pval)))
# NOTE: Genes MUST be stored in list format, not as a dataframe.
DEGs_df <- DEGs_df %>%
dplyr::distinct_at("SYMBOL", .keep_all = TRUE) %>%
dplyr::filter(!is.na(padj)) %>%
dplyr::arrange(desc(log2FoldChange))
DEGs_list <- DEGs_df$log2FoldChange
names(DEGs_list) <- DEGs_df$SYMBOL
#****************************************************************************#
#                         DEFINE scoreType PARAMETER                         #
#****************************************************************************#
# Define score type in fgseaMultilevel() based on fold change values.
# NOTE: Use "pos", if you are ONLY interested in activated pathways.
# NOTE: Use "neg", if you are ONLY interested in inhibited pathways.
# NOTE: Else, use "std" for both activated & inhibited pathways.
score_type <- dplyr::if_else(max(DEGs_list) > 0 & min(DEGs_list) < 0, "std",
dplyr::if_else(max(DEGs_list) < 0 & min(DEGs_list) < 0, "neg", "pos"))
#****************************************************************************#
#                      IMPORT YOUR GENE SETS OF INTEREST                     #
#****************************************************************************#
# NOTE: Unlike clusterProfiler::GSEA(), fgsea::fgseaMultilevel() needs gene
# sets in a specific list format
# NOTE: If you run multiple gene sets like C5 and C2 together, padj will not
# be significant as there will be too many multiple comparisons.
gmt <- fgsea::gmtPathways(gmt_file)
gmt_name <- gsub(pattern="^.*/|v2023.*$", replacement="", x=gmt_file)
# From each gene set, remove genes that are absent in your DEGs_list
for (i in 1:length(gmt)){
gmt[[i]] <- gmt[[i]][gmt[[i]] %in% names(DEGs_list)]
}
#****************************************************************************#
#                                  RUN fGSEA                                 #
#****************************************************************************#
fgsea <- fgsea::fgseaMultilevel(pathways = gmt,
stats = DEGs_list,
scoreType = score_type,
sampleSize = 101,
minSize = 1,
maxSize = length(DEGs_list) - 1,
eps = 1e-50,
nproc = 0,
gseaParam = 1,
BPPARAM = NULL,
nPermSimple = 10000)
#****************************************************************************#
#                               FORMAT RESULTS                               #
#****************************************************************************#
# NOTE: Output of fgsea is a data.table & data.frame.
# "leadingEdge" column is a list of genes.
# So, DO NOT FORCE the output of fgsea to a dataframe as this will lead to
# data loss from "leadingEdge" column & affect plotting using fgsea::plotEnrichment()
# Reformat the output
gsea_results <- fgsea %>%
dplyr::mutate(abs_NES = abs(NES)) %>%
dplyr::arrange(desc(abs_NES)) %>%
dplyr::mutate(Direction = dplyr::if_else(NES > 0, "Upregualted", "Downregulated"))
# If you ordered your gene list based on fold change, then +ve NES indicates
# that the genes in this gene set are mostly at the top of your gene list
# (hence, most of them are upregulated) and -ve NES indicates that the genes
# in this gene set are mostly at the bottom of your gene list (hence, most
# of them are downregulated)
# Identify overlapping pathways and collapse them into major pathways
concise_gsea_results <- fgsea::collapsePathways(fgseaRes = gsea_results,
pathways = gmt,
stats = DEGs_list)
# Filter out overlapping pathways
concise_gsea_results <- gsea_results %>%
dplyr::filter(pathway %in% concise_gsea_results$mainPathways)
# Function to convert genelist to df
convert_genelist_to_df <- function(gsea_results){
# Create a dataframe containing genes for each pathway
max_len <- max(unlist(lapply(X=stringr::str_split(string = gsea_results$leadingEdge, pattern = ","), FUN=length)))
df <- data.frame(matrix(NA, nrow=max_len))
# Add genes from each pathway to a separate column
for (i in 1:nrow(gsea_results)){
l1 <- unlist(stringr::str_split(string = unlist(gsea_results$leadingEdge[[i]]), pattern = ","))
# If leading edge column has ENSEMBL_IDs, convert them to SYMBOL
if (length(intersect(l1, annotations$ENSEMBL_ID)) > length(intersect(l1, annotations$SYMBOL))){
l1 <- annotations %>%
dplyr::filter(ENSEMBL_ID %in% l1) %>%
dplyr::select(SYMBOL) %>%
unlist(., use.names=FALSE)
}
l1 <- c(l1, rep(x=NA, times=max_len-length(l1)))
df <- dplyr::bind_cols(df, l1)
colnames(df)[i+1] <- gsea_results$pathway[i]
}
# Remove the dummy column containing NAs
df <- df[,-1]
return(df)
}
if(nrow(gsea_results) > 0){
gsea_gene_df <- convert_genelist_to_df(gsea_results)
} else{
gsea_gene_df <- data.frame(matrix(NA, nrow=1))
}
if(nrow(concise_gsea_results) > 0){
concise_gsea_gene_df <- convert_genelist_to_df(concise_gsea_results)
} else{
concise_gsea_gene_df <- data.frame(matrix(NA, nrow=1))
}
# Save the results in excel file
wb <- openxlsx::createWorkbook()
openxlsx::addWorksheet(wb, sheetName="gsea_full")
openxlsx::writeData(wb, sheet="gsea_full", x=gsea_results, rowNames=FALSE)
openxlsx::addWorksheet(wb, sheetName="gsea_concise")
openxlsx::writeData(wb, sheet="gsea_concise", x=concise_gsea_results, rowNames=FALSE)
openxlsx::addWorksheet(wb, sheetName="gsea_full_genes")
openxlsx::writeData(wb, sheet="gsea_full_genes", x=gsea_gene_df, rowNames=FALSE)
openxlsx::addWorksheet(wb, sheetName="gsea_concise_genes")
openxlsx::writeData(wb, sheet="gsea_concise_genes", x=concise_gsea_gene_df, rowNames=FALSE)
openxlsx::saveWorkbook(wb, file = paste0(results_path, gmt_name, "fGSEA_Results.xlsx"),
overwrite = TRUE)
}
DEGs_df <- read.xlsx(paste0(parent_path, "pg_matrix.xlsx"))
# List all gmt files
gmt_files <- list.files("C:/Users/kailasamms/Documents/GitHub/R-Scripts/GSEA_genesets/Mouse", full.names = TRUE)
# Loop over each gmt file and perform GSEA analysis
for (f in gmt_files){
fgsea(DEGs_df, f)
}
# Import DEGs dataframe with "SYMBOL", "padj" and "log2FoldChange" columns
DEGs_df <- read.xlsx(paste0(parent_path, "pg_matrix.xlsx"))
# List all gmt files
gmt_files <- list.files("C:/Users/kailasamms/Documents/GitHub/R-Scripts/GSEA_genesets/Mouse", full.names = TRUE)
species <- "Mus musculus"
annotations <- get_annotation(species)
species <- "Mus musculus"
annotations <- get_annotations(species)
source("C:/Users/kailasamms/Documents/GitHub/R-Scripts/RNASeq_DESeq2_Functions.R")
species <- "Mus musculus"
annotations <- get_annotations(species)
# Import DEGs dataframe with "SYMBOL", "padj" and "log2FoldChange" columns
DEGs_df <- read.xlsx(paste0(parent_path, "pg_matrix.xlsx"))
# List all gmt files
gmt_files <- list.files("C:/Users/kailasamms/Documents/GitHub/R-Scripts/GSEA_genesets/Mouse", full.names = TRUE)
# Loop over each gmt file and perform GSEA analysis
for (f in gmt_files){
fgsea(DEGs_df, f, annotations)
}
